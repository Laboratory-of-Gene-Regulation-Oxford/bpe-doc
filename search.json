[
  {
    "objectID": "bpe-doc.html",
    "href": "bpe-doc.html",
    "title": "bpe-doc",
    "section": "",
    "text": "This site provides high level documentation of bpe collection of facilities to process and analyse gene regulation experiemental results."
  },
  {
    "objectID": "bpe-doc.html#bam-peak-enhancer-bpe-overview",
    "href": "bpe-doc.html#bam-peak-enhancer-bpe-overview",
    "title": "bpe-doc",
    "section": "",
    "text": "This site provides high level documentation of bpe collection of facilities to process and analyse gene regulation experiemental results."
  },
  {
    "objectID": "bpe-doc.html#how-to-contribute-documentation",
    "href": "bpe-doc.html#how-to-contribute-documentation",
    "title": "bpe-doc",
    "section": "How to contribute documentation",
    "text": "How to contribute documentation\n\nEdit in GitHub - for small changes\n\nOpen the repository in github.com for this documentation site.\nBrowse to the file\n\n*.qmd (or .md) files in your content folders.\n\nClick the pencil icon (‚ÄúEdit this file‚Äù)\n\nGitHub opens an in-browser editor for that file.\n\nMake the change and commit\n\nAdd a short commit message.\nEither commit directly to the main branch (if allowed) or create a new branch and open a pull request.\n\nApproval of change and deployment\n\nYour changes may need approval, which case a pull request will be set up and once approved the site will be automatically rebuilt.\n\n\n\n\nEdit locally - for larger changes\n\nOne-time setup\n\nClone the repository to your local machine\n\ngit clone https://github.com/Laboratory-of-Gene-Regulation-Oxford/bpe-doc.git or clone using vs code git extension.\n\nSet up your local environment\n\nFollow any setup instructions specific to this repository.\n\n\n\n\nMaking changes\n\nOpen the repository in your local editor\n\nOpen the folder you cloned in your code editor (e.g., VS Code, RStudio).\n\nEdit the files\n\nMake changes to the *.qmd (or .md) files as needed.\n\nPreview your changes\n\nUse Quarto‚Äôs preview features to see how your changes will look.\n\nCommit and push your changes\n\nUse git to commit your changes with a descriptive message.\nPush your changes to your fork or branch on GitHub.\n\nCreate a pull request\n\nOpen a pull request on GitHub to propose your changes for review.\n\nApproval of change and deployment\n\nOnce your pull request is approved, the site will be automatically rebuilt and your changes will go live.\n\n\n\n\nQuarto\nQuarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "bpe-doc",
    "section": "",
    "text": "This site provides high level documentation of bpe collection of facilities to process and analyse gene regulation experiemental results."
  },
  {
    "objectID": "index.html#bam-peak-enhancer-bpe-overview",
    "href": "index.html#bam-peak-enhancer-bpe-overview",
    "title": "bpe-doc",
    "section": "",
    "text": "This site provides high level documentation of bpe collection of facilities to process and analyse gene regulation experiemental results."
  },
  {
    "objectID": "index.html#documentation-topics",
    "href": "index.html#documentation-topics",
    "title": "bpe-doc",
    "section": "Documentation Topics",
    "text": "Documentation Topics\n\n\n\n\n\nüîß\n\n\nShell Scripts Guide\n\n\nLearn how to automate sequence processing workflows with shell scripts\n\n\n\n\n\n\n\n\n‚öôÔ∏è\n\n\nCGAT Pipeline Basics\n\n\nLearn how to run and configure CGAT computational biology pipelines\n\n\n\n\n\n\n\n\nüìö\n\n\nWhy Quarto\n\n\nLearn about the rationale for using Quarto and GitHub Pages"
  },
  {
    "objectID": "index.html#how-to-contribute-documentation",
    "href": "index.html#how-to-contribute-documentation",
    "title": "bpe-doc",
    "section": "How to contribute documentation",
    "text": "How to contribute documentation\n\nEdit in GitHub - for small changes\n\nOpen the repository in github.com for this documentation site.\nBrowse to the file\n\n*.qmd (or .md) files in your content folders.\n\nClick the pencil icon (‚ÄúEdit this file‚Äù)\n\nGitHub opens an in-browser editor for that file.\n\nMake the change and commit\n\nAdd a short commit message.\nEither commit directly to the main branch (if allowed) or create a new branch and open a pull request.\n\nApproval of change and deployment\n\nYour changes may need approval, which case a pull request will be set up and once approved the site will be automatically rebuilt.\n\n\n\n\nEdit locally - for larger changes\n\nOne-time setup\n\nClone the repository to your local machine\n\ngit clone https://github.com/Laboratory-of-Gene-Regulation-Oxford/bpe-doc.git or clone using vs code git extension.\n\nSet up your local environment\n\nFollow any setup instructions specific to this repository.\n\n\n\n\nMaking changes\n\nOpen the repository in your local editor\n\nOpen the folder you cloned in your code editor (e.g., VS Code, RStudio).\n\nEdit the files\n\nMake changes to the *.qmd (or .md) files as needed.\n\nPreview your changes\n\nUse Quarto‚Äôs preview features to see how your changes will look.\n\nCommit and push your changes\n\nUse git to commit your changes with a descriptive message.\nPush your changes to your fork or branch on GitHub.\n\nCreate a pull request\n\nOpen a pull request on GitHub to propose your changes for review.\n\nApproval of change and deployment\n\nOnce your pull request is approved, the site will be automatically rebuilt and your changes will go live.\n\n\n\n\nQuarto\nQuarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "why-quarto.html",
    "href": "why-quarto.html",
    "title": "Why use quarto for GitHub Pages docs?",
    "section": "",
    "text": "Why use quarto for GitHub Pages docs?\nThis page is generated by an LLM\nYou‚Äôd consider Quarto for user manuals on GitHub Pages if you want a repeatable, automated docs pipeline rather than hand-crafted web pages. In practice, it helps most if your manuals are versioned, somewhat technical, or need to stay in sync with code.\nHere are the main reasons.\n\n1. Reproducible, versioned docs with your code\n\nManuals live in the same repo as your code or pipelines.\nYou write in plain text (Markdown, R Markdown, Jupyter, etc.), commit, and Quarto renders them to a static site that GitHub Pages serves.\nEach branch or tag of the repo can correspond to a specific version of the manual, so docs can track e.g.¬†pipeline versions.\n\nWhen it helps:\n\nLab workflows or bioinformatics pipelines that keep changing.\nYou want ‚Äúthe docs for release v1.2.3‚Äù to be reproducible from the repo state.\n\n\n\n2. Single source, many outputs (HTML, PDF, etc.)\n\nQuarto can build HTML for GitHub Pages, but also PDF (via LaTeX), Word, or slides from the same source.\nYou avoid copy‚Äìpasting between ‚Äúonline help,‚Äù ‚Äúhandout PDF,‚Äù and ‚Äúslide deck for training.‚Äù\n\nWhen it helps:\n\nOnboarding new lab members with a mix of web manuals, printable guides, and training slides.\n\n\n\n3. Nice structure and navigation ‚Äúfor free‚Äù\n\nYou define a simple YAML project file that describes the site (chapters, sections, sidebar).\nQuarto handles navigation, table of contents, cross-references, citations, search (with some config), and consistent styling.\nYou focus on content, not HTML or CSS.\n\nWhen it helps:\n\nYou want something that feels like a small docs site / book rather than a loose set of Markdown files.\n\n\n\n4. Good for technical and computational examples\n\nFirst-class support for executable code blocks (R, Python, Julia, etc.) if you ever want that.\nYou can show examples, figures, and outputs generated directly from code and data, ensuring they stay up to date when you re-render.\n\nWhen it helps:\n\nManuals for analysis workflows, QC steps, data formats, or example analyses.\n\nIf you do not need executable code, you can still just write plain Markdown and ignore that part.\n\n\n5. Automation and CI fit nicely with GitHub\n\nYou can wire Quarto to GitHub Actions so that on every push to main (or to a docs branch), the site re-builds and redeploys automatically.\nThis makes it low-friction to keep manuals current: update text, commit, push, done.\n\nWhen it helps:\n\nMultiple contributors updating manuals.\nYou want docs updates reviewed by PR like code.\n\n\n\n6. Separation of content from presentation\n\nStyling, logos, and layout live in a small number of config/theme files.\nThe actual manual content stays in clean, readable text that is easy to review in diffs.\nIf later you change branding or layout, you do it once and rebuild.\n\nWhen it helps:\n\nYou expect the look and feel to evolve, but you do not want to rewrite content each time.\n\n\n\n7. Why not use Quarto?\nYou might not want Quarto if:\n\nYou just need one or two simple static pages that rarely change. Plain Markdown in GitHub Pages or a simple README might be enough.\nYou want fully WYSIWYG editing by non-technical users with no interest in Git, Markdown, or PRs.\nYour users will only ever consume PDF and you are happy writing in Word or Google Docs.\n\n\nIf you tell me roughly what your ‚ÄúLGR team documentation framework‚Äù should look like (size of manual, who edits it, how technical the audience is), I can sketch a concrete ‚Äúyes or no‚Äù on Quarto for your case and, if yes, the rough repo structure you‚Äôd use."
  },
  {
    "objectID": "cgat-basics.html",
    "href": "cgat-basics.html",
    "title": "CGAT Pipeline Basics",
    "section": "",
    "text": "CGAT pipelines provide a framework for reproducible computational biology workflows. This guide covers the basics of running CGAT pipelines."
  },
  {
    "objectID": "cgat-basics.html#overview",
    "href": "cgat-basics.html#overview",
    "title": "CGAT Pipeline Basics",
    "section": "",
    "text": "CGAT pipelines provide a framework for reproducible computational biology workflows. This guide covers the basics of running CGAT pipelines."
  },
  {
    "objectID": "cgat-basics.html#what-are-cgat-pipelines",
    "href": "cgat-basics.html#what-are-cgat-pipelines",
    "title": "CGAT Pipeline Basics",
    "section": "What are CGAT Pipelines?",
    "text": "What are CGAT Pipelines?\nCGAT pipelines are a collection of workflows built using the CGAT-core framework. They provide standardized, tested pipelines for common bioinformatics analyses including:\n\nRNA-seq analysis\nChIP-seq analysis\nSingle-cell analysis\nVariant calling\nAnd more"
  },
  {
    "objectID": "cgat-basics.html#installation",
    "href": "cgat-basics.html#installation",
    "title": "CGAT Pipeline Basics",
    "section": "Installation",
    "text": "Installation\n\nUsing Conda (Recommended)\n# Create a new conda environment\nconda create -n cgat-pipelines python=3.9\n\n# Activate the environment\nconda activate cgat-pipelines\n\n# Install CGAT-core and pipelines\nconda install -c conda-forge -c bioconda cgatcore cgat-apps"
  },
  {
    "objectID": "cgat-basics.html#basic-pipeline-structure",
    "href": "cgat-basics.html#basic-pipeline-structure",
    "title": "CGAT Pipeline Basics",
    "section": "Basic Pipeline Structure",
    "text": "Basic Pipeline Structure\nCGAT pipelines follow a consistent structure:\nproject/\n‚îú‚îÄ‚îÄ pipeline.yml          # Configuration file\n‚îú‚îÄ‚îÄ pipeline_name.py      # Pipeline script\n‚îî‚îÄ‚îÄ data/                 # Input data directory"
  },
  {
    "objectID": "cgat-basics.html#running-a-pipeline",
    "href": "cgat-basics.html#running-a-pipeline",
    "title": "CGAT Pipeline Basics",
    "section": "Running a Pipeline",
    "text": "Running a Pipeline\n\n1. Configure the Pipeline\nEach pipeline requires a configuration file (pipeline.yml). Generate a default configuration:\n# Navigate to your project directory\ncd my_project/\n\n# Generate default configuration\ncgatflow &lt;pipeline_name&gt; config\n\n# This creates pipeline.yml - edit it to match your requirements\n\n\n2. Check What Will Run\nBefore executing, check what tasks will be performed:\n# Show tasks without executing\ncgatflow &lt;pipeline_name&gt; show full\n\n\n3. Execute the Pipeline\n# Run the pipeline locally\ncgatflow &lt;pipeline_name&gt; make full -v5\n\n# Run with specific number of jobs in parallel\ncgatflow &lt;pipeline_name&gt; make full -v5 -p 10\n\n\n4. Generate a Report\nAfter completion, generate an HTML report:\ncgatflow &lt;pipeline_name&gt; make build_report"
  },
  {
    "objectID": "cgat-basics.html#common-pipeline-commands",
    "href": "cgat-basics.html#common-pipeline-commands",
    "title": "CGAT Pipeline Basics",
    "section": "Common Pipeline Commands",
    "text": "Common Pipeline Commands\n\nCheck Pipeline Status\n# Show pipeline targets\ncgatflow &lt;pipeline_name&gt; show full\n\n# Show task state\ncgatflow &lt;pipeline_name&gt; show state\n\n\nRunning Specific Tasks\n# Run only specific targets\ncgatflow &lt;pipeline_name&gt; make &lt;target_name&gt; -v5\n\n# For example, in RNA-seq pipeline:\ncgatflow readqc make full -v5\n\n\nCleaning Up\n# Remove generated files (be careful!)\ncgatflow &lt;pipeline_name&gt; clean"
  },
  {
    "objectID": "cgat-basics.html#configuration-file-pipeline.yml",
    "href": "cgat-basics.html#configuration-file-pipeline.yml",
    "title": "CGAT Pipeline Basics",
    "section": "Configuration File (pipeline.yml)",
    "text": "Configuration File (pipeline.yml)\nThe pipeline.yml file controls pipeline behavior. Key sections include:\n# Example pipeline.yml structure\n\n# Input/Output\ninput:\n  pattern: \"*.fastq.gz\"\n  \n# Processing parameters\nalignment:\n  genome: \"hg38\"\n  aligner: \"star\"\n  threads: 8\n\n# Quality control\nqc:\n  min_quality: 20\n  adapter_file: \"adapters.fa\""
  },
  {
    "objectID": "cgat-basics.html#example-rna-seq-pipeline",
    "href": "cgat-basics.html#example-rna-seq-pipeline",
    "title": "CGAT Pipeline Basics",
    "section": "Example: RNA-seq Pipeline",
    "text": "Example: RNA-seq Pipeline\n# 1. Set up project\nmkdir rnaseq_project && cd rnaseq_project\nmkdir data/\n\n# 2. Link or copy your FASTQ files to data/\nln -s /path/to/fastq/*.fastq.gz data/\n\n# 3. Generate configuration\ncgatflow rnaseq config\n\n# 4. Edit pipeline.yml to set:\n#    - Reference genome\n#    - Gene annotations\n#    - Analysis parameters\n\n# 5. Check what will run\ncgatflow rnaseq show full\n\n# 6. Execute pipeline\ncgatflow rnaseq make full -v5 -p 8\n\n# 7. Generate report\ncgatflow rnaseq make build_report"
  },
  {
    "objectID": "cgat-basics.html#running-on-a-cluster",
    "href": "cgat-basics.html#running-on-a-cluster",
    "title": "CGAT Pipeline Basics",
    "section": "Running on a Cluster",
    "text": "Running on a Cluster\nCGAT pipelines support cluster execution:\n# Configure cluster in pipeline.yml\ncluster:\n  queue_manager: \"slurm\"\n  queue: \"short\"\n  memory_default: \"4G\"\n\n# Run on cluster\ncgatflow &lt;pipeline_name&gt; make full -v5 --cluster-queue=short"
  },
  {
    "objectID": "cgat-basics.html#best-practices",
    "href": "cgat-basics.html#best-practices",
    "title": "CGAT Pipeline Basics",
    "section": "Best Practices",
    "text": "Best Practices\n\nAlways work in a conda environment to manage dependencies\nUse version control for your configuration files\nTest on small datasets before running full analyses\nKeep logs - use -v5 for verbose logging\nCheck configuration thoroughly before long runs\nMonitor resource usage to optimize cluster parameters\nGenerate reports to document results"
  },
  {
    "objectID": "cgat-basics.html#troubleshooting",
    "href": "cgat-basics.html#troubleshooting",
    "title": "CGAT Pipeline Basics",
    "section": "Troubleshooting",
    "text": "Troubleshooting\n\nPipeline Fails\n# Check logs in _log directory\nls _log/\n\n# Re-run with verbose output\ncgatflow &lt;pipeline_name&gt; make full -v5\n\n\nDependency Issues\n# Update conda environment\nconda update --all\n\n# Reinstall if needed\nconda install --force-reinstall cgatcore"
  },
  {
    "objectID": "cgat-basics.html#further-resources",
    "href": "cgat-basics.html#further-resources",
    "title": "CGAT Pipeline Basics",
    "section": "Further Resources",
    "text": "Further Resources\n\nCGAT-core documentation\nCGAT pipelines GitHub\nPipeline-specific documentation in each pipeline repository"
  },
  {
    "objectID": "shell-scripts.html",
    "href": "shell-scripts.html",
    "title": "Using Shell Scripts for Sequence Processing",
    "section": "",
    "text": "This guide covers how to use shell scripts to run sequence processing programs efficiently."
  },
  {
    "objectID": "shell-scripts.html#overview",
    "href": "shell-scripts.html#overview",
    "title": "Using Shell Scripts for Sequence Processing",
    "section": "",
    "text": "This guide covers how to use shell scripts to run sequence processing programs efficiently."
  },
  {
    "objectID": "shell-scripts.html#basic-shell-script-structure",
    "href": "shell-scripts.html#basic-shell-script-structure",
    "title": "Using Shell Scripts for Sequence Processing",
    "section": "Basic Shell Script Structure",
    "text": "Basic Shell Script Structure\nShell scripts provide a way to automate sequence processing workflows. Here‚Äôs a basic template:\n#!/bin/bash\n# Script: process_sequences.sh\n# Description: Process sequencing data\n\n# Set error handling\nset -e  # Exit on error\nset -u  # Exit on undefined variable\nset -o pipefail  # Exit on pipe failure\n\n# Define input/output paths\nINPUT_DIR=\"data/raw\"\nOUTPUT_DIR=\"data/processed\"\n\n# Create output directory if it doesn't exist\nmkdir -p \"$OUTPUT_DIR\"\n\necho \"Starting sequence processing...\"\n# Your processing commands here"
  },
  {
    "objectID": "shell-scripts.html#running-programs-in-shell-scripts",
    "href": "shell-scripts.html#running-programs-in-shell-scripts",
    "title": "Using Shell Scripts for Sequence Processing",
    "section": "Running Programs in Shell Scripts",
    "text": "Running Programs in Shell Scripts\n\nBasic Command Execution\n# Run a single command\nprogram_name input.fastq &gt; output.txt\n\n# Run with multiple parameters\nprogram_name --input input.fastq --output output.bam --threads 4\n\n\nError Checking\n# Check if command succeeded\nif ! program_name input.fastq &gt; output.txt; then\n    echo \"Error: Processing failed\" &gt;&2\n    exit 1\nfi\n\n# Alternative using set -e (recommended)\nset -e\nprogram_name input.fastq &gt; output.txt\n\n\nProcessing Multiple Files\n# Loop through all FASTQ files\nfor file in \"$INPUT_DIR\"/*.fastq; do\n    basename=$(basename \"$file\" .fastq)\n    echo \"Processing $basename...\"\n    program_name \"$file\" &gt; \"$OUTPUT_DIR/${basename}.processed.txt\"\ndone"
  },
  {
    "objectID": "shell-scripts.html#best-practices",
    "href": "shell-scripts.html#best-practices",
    "title": "Using Shell Scripts for Sequence Processing",
    "section": "Best Practices",
    "text": "Best Practices\n\nAlways use error handling with set -e\nQuote variables to handle spaces in filenames: \"$variable\"\nLog output to track progress and debug issues\nUse meaningful variable names for clarity\nComment your code to explain complex operations\nTest on small datasets before running on full data"
  },
  {
    "objectID": "shell-scripts.html#example-complete-processing-pipeline",
    "href": "shell-scripts.html#example-complete-processing-pipeline",
    "title": "Using Shell Scripts for Sequence Processing",
    "section": "Example: Complete Processing Pipeline",
    "text": "Example: Complete Processing Pipeline\n#!/bin/bash\nset -euo pipefail\n\n# Configuration\nINPUT_DIR=\"data/raw\"\nOUTPUT_DIR=\"data/processed\"\nTHREADS=8\nLOG_FILE=\"processing.log\"\n\n# Create directories\nmkdir -p \"$OUTPUT_DIR\"\n\n# Start logging\nexec &gt; &gt;(tee \"$LOG_FILE\") 2&gt;&1\necho \"Pipeline started: $(date)\"\n\n# Process each sample\nfor fastq in \"$INPUT_DIR\"/*.fastq.gz; do\n    sample=$(basename \"$fastq\" .fastq.gz)\n    echo \"Processing sample: $sample\"\n    \n    # Quality control\n    fastqc \"$fastq\" -o \"$OUTPUT_DIR\"\n    \n    # Alignment\n    bwa mem -t \"$THREADS\" reference.fa \"$fastq\" | \\\n        samtools sort -@ \"$THREADS\" -o \"$OUTPUT_DIR/${sample}.bam\"\n    \n    # Index\n    samtools index \"$OUTPUT_DIR/${sample}.bam\"\ndone\n\necho \"Pipeline completed: $(date)\""
  },
  {
    "objectID": "shell-scripts.html#further-resources",
    "href": "shell-scripts.html#further-resources",
    "title": "Using Shell Scripts for Sequence Processing",
    "section": "Further Resources",
    "text": "Further Resources\n\nBash scripting guide\nShell script best practices\nWorkflow management systems (Snakemake, Nextflow)"
  }
]